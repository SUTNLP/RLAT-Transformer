{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "167fc474c61b403e82cfab36e041c297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a67cdafbb46e4844a91888cddab9951c",
              "IPY_MODEL_38d294bc14424223b37d187590701022",
              "IPY_MODEL_9807dc09f9c5402395466b55f451deb2"
            ],
            "layout": "IPY_MODEL_1e927a9947c2478eba65bad5f52b4b08"
          }
        },
        "a67cdafbb46e4844a91888cddab9951c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d08bd74e725424c9d5505d91547768b",
            "placeholder": "​",
            "style": "IPY_MODEL_ca606609b41e4cac8f321c9059fcbf7e",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "38d294bc14424223b37d187590701022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311d3520e27f4b6c8d28a76b3477941d",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e4719d6ed6d41c0b8fab61013b8cb7b",
            "value": 52
          }
        },
        "9807dc09f9c5402395466b55f451deb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a93159668d4c33be84a426fe73178d",
            "placeholder": "​",
            "style": "IPY_MODEL_3059c7c30770496480f6ac6c5463f9ed",
            "value": " 52.0/52.0 [00:00&lt;00:00, 854B/s]"
          }
        },
        "1e927a9947c2478eba65bad5f52b4b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d08bd74e725424c9d5505d91547768b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca606609b41e4cac8f321c9059fcbf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311d3520e27f4b6c8d28a76b3477941d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4719d6ed6d41c0b8fab61013b8cb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8a93159668d4c33be84a426fe73178d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3059c7c30770496480f6ac6c5463f9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3edd9b987515494791d4d2224481eadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6fb5c1d61f34a9385bc50e1f87447a0",
              "IPY_MODEL_c5049121269c484a84cb1afdbd8de15a",
              "IPY_MODEL_e784000b752449b9a9b8b7719e464d4f"
            ],
            "layout": "IPY_MODEL_3a780e04baa949f68580150338c357c4"
          }
        },
        "f6fb5c1d61f34a9385bc50e1f87447a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89e7eb9f5c14375b8f0ab61f68153c8",
            "placeholder": "​",
            "style": "IPY_MODEL_fddaec38edec48f1be33e31ad7fe231a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c5049121269c484a84cb1afdbd8de15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553025da88674d348bc2f2abbbab498d",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86cfd6cdf5164091998dc7f2d680eca0",
            "value": 580
          }
        },
        "e784000b752449b9a9b8b7719e464d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fa48508494d49efbbf2e23624bd8180",
            "placeholder": "​",
            "style": "IPY_MODEL_370da98313384bcd8c76f8953cf9128a",
            "value": " 580/580 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "3a780e04baa949f68580150338c357c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89e7eb9f5c14375b8f0ab61f68153c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fddaec38edec48f1be33e31ad7fe231a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553025da88674d348bc2f2abbbab498d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86cfd6cdf5164091998dc7f2d680eca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fa48508494d49efbbf2e23624bd8180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370da98313384bcd8c76f8953cf9128a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1729e26425c14aab8f83d0078f4266d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2e8904de1dc4804b4b4ef7e968f6878",
              "IPY_MODEL_a496638544744f31a2200134fe033891",
              "IPY_MODEL_e533e3dde2014b5ababf64ddd58165d7"
            ],
            "layout": "IPY_MODEL_269877967fd948f8b76fe0376367457c"
          }
        },
        "a2e8904de1dc4804b4b4ef7e968f6878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96de9daac2d446fda452d82be650ac0f",
            "placeholder": "​",
            "style": "IPY_MODEL_75f79f8d39d440a2bb485bede8b7cfb8",
            "value": "Downloading (…)&quot;spm.model&quot;;: 100%"
          }
        },
        "a496638544744f31a2200134fe033891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1632aef2ee6e4cabb067ae1f727a4203",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec1a8594b4fb4fc78f515d37886a31a6",
            "value": 2464616
          }
        },
        "e533e3dde2014b5ababf64ddd58165d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f15de7dd41524a2aba5117cecc8541d9",
            "placeholder": "​",
            "style": "IPY_MODEL_76bb690042924eee8b91d482c33019d4",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 21.5MB/s]"
          }
        },
        "269877967fd948f8b76fe0376367457c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96de9daac2d446fda452d82be650ac0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f79f8d39d440a2bb485bede8b7cfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1632aef2ee6e4cabb067ae1f727a4203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1a8594b4fb4fc78f515d37886a31a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f15de7dd41524a2aba5117cecc8541d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76bb690042924eee8b91d482c33019d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fd932f3b0a4fa1b919cd9a397617c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5579b53ddfa46919d362f6b4b0ca5ed",
              "IPY_MODEL_daa8ace085d14ed987d1636e411d40f7",
              "IPY_MODEL_c173721c90a84c35a848580548b92994"
            ],
            "layout": "IPY_MODEL_fa97ddf181b347e3accf5ee8c86d0a4f"
          }
        },
        "b5579b53ddfa46919d362f6b4b0ca5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3e70ef79e54c22945b93c9c663de5c",
            "placeholder": "​",
            "style": "IPY_MODEL_80b53483bceb415082b6303d43314ecb",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "daa8ace085d14ed987d1636e411d40f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ce4fdbe6bf43619101fd8e0ff1e436",
            "max": 873673253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d046cba47dd490cad0882a7323565bf",
            "value": 873673253
          }
        },
        "c173721c90a84c35a848580548b92994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91be9c5e31b43418f7ee568687c2855",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac707b38fb74b9eb26abdaab77142d0",
            "value": " 874M/874M [00:10&lt;00:00, 71.6MB/s]"
          }
        },
        "fa97ddf181b347e3accf5ee8c86d0a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3e70ef79e54c22945b93c9c663de5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b53483bceb415082b6303d43314ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ce4fdbe6bf43619101fd8e0ff1e436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d046cba47dd490cad0882a7323565bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a91be9c5e31b43418f7ee568687c2855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac707b38fb74b9eb26abdaab77142d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_aggregated.csv\n",
        "! pip install transformers\n",
        "! pip install optuna\n",
        "! pip install sentencepiece\n",
        "! pip install gdown\n",
        "! pip install sentence-transformers\n",
        "\n",
        "! gdown \"1UjEYJOauAanJ0UzuSRrCVLn6GHvJyWus&confirm=t\"\n",
        "! gdown --id 16YwJWsljY2r2R4Fzh4xLilSbPjowlZr_\n",
        "! gdown --id 1YDr6ejvJPiQL3HAWR7i71GanzWsfxlQo\n",
        "! gdown --id 11hYRWLmxyWd3j-rQsKTPS1fCuQvSFWcl\n",
        "! gdown --id 1z2FvuIDZPUTKXJ0_Z6VBvFEzRteTLIa5\n",
        "! gdown --id 1hEX89Ffv_lu8uIoOuX5trX0RqYFiI0Of\n",
        "! gdown --id 1MD4pEghAgkpkxhr9Tyx_cEqGggki_XBu\n",
        "! gdown --id 1zCW194SsKQ6U3sUEJ1eB7PiIKcOfdki0\n",
        "! gdown --id 1yh77Xp7mwjjaYrPX6Y8OQchXSSqYIso-\n",
        "\n",
        "! gdown \"1-2pA6nIe74QSNzinswFKCxbcIMgu6m3T&confirm=t\"\n",
        "\n",
        "! yes A | unzip train_data.zip\n",
        "! unzip eval_A.zip\n",
        "! unzip eval_B.zip\n",
        "! unzip eval_C.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NDs2coVdV8H",
        "outputId": "73322589-53d0-4c14-ec89-1ecd8097d0e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-23 13:56:17--  https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_aggregated.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3846925 (3.7M) [text/plain]\n",
            "Saving to: ‘edos_labelled_aggregated.csv’\n",
            "\n",
            "\r          edos_labe   0%[                    ]       0  --.-KB/s               \redos_labelled_aggre 100%[===================>]   3.67M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-02-23 13:56:18 (240 MB/s) - ‘edos_labelled_aggregated.csv’ saved [3846925/3846925]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.22.4)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.26.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=4c5f610f59708cfd4601d1d33599901beaf61eeb2878ddc6ef59d8eb8b0db32a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UjEYJOauAanJ0UzuSRrCVLn6GHvJyWus&confirm=t\n",
            "To: /content/train_data.zip\n",
            "100% 87.1M/87.1M [00:01<00:00, 51.0MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16YwJWsljY2r2R4Fzh4xLilSbPjowlZr_\n",
            "To: /content/eval_A.zip\n",
            "100% 125k/125k [00:00<00:00, 84.5MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YDr6ejvJPiQL3HAWR7i71GanzWsfxlQo\n",
            "To: /content/eval_B.zip\n",
            "100% 32.6k/32.6k [00:00<00:00, 35.7MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11hYRWLmxyWd3j-rQsKTPS1fCuQvSFWcl\n",
            "To: /content/eval_C.zip\n",
            "100% 32.6k/32.6k [00:00<00:00, 30.3MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z2FvuIDZPUTKXJ0_Z6VBvFEzRteTLIa5\n",
            "To: /content/gab_1M_unlabelled.csv\n",
            "100% 95.9M/95.9M [00:00<00:00, 173MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hEX89Ffv_lu8uIoOuX5trX0RqYFiI0Of\n",
            "To: /content/reddit_1M_unlabelled.csv\n",
            "100% 98.0M/98.0M [00:01<00:00, 96.7MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MD4pEghAgkpkxhr9Tyx_cEqGggki_XBu\n",
            "To: /content/good.pk\n",
            "100% 1.84M/1.84M [00:00<00:00, 187MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zCW194SsKQ6U3sUEJ1eB7PiIKcOfdki0\n",
            "To: /content/dev_task_b_labels.csv\n",
            "100% 20.4k/20.4k [00:00<00:00, 32.3MB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yh77Xp7mwjjaYrPX6Y8OQchXSSqYIso-\n",
            "To: /content/dev_task_c_labels.csv\n",
            "100% 33.5k/33.5k [00:00<00:00, 34.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2pA6nIe74QSNzinswFKCxbcIMgu6m3T&confirm=t\n",
            "To: /content/best_ch.pt\n",
            "100% 5.21G/5.21G [01:12<00:00, 72.3MB/s]\n",
            "Archive:  train_data.zip\n",
            "  inflating: train_all_tasks.csv     \n",
            "replace reddit_1M_unlabelled.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: reddit_1M_unlabelled.csv  \n",
            "  inflating: gab_1M_unlabelled.csv   \n",
            " extracting: EXAMPLE_SUBMISSION_dev_task_a.zip  \n",
            " extracting: EXAMPLE_SUBMISSION_dev_task_b.zip  \n",
            " extracting: EXAMPLE_SUBMISSION_dev_task_c.zip  \n",
            "Archive:  eval_A.zip\n",
            "  inflating: dev_task_a_entries.csv  \n",
            "Archive:  eval_B.zip\n",
            "  inflating: dev_task_b_entries.csv  \n",
            "Archive:  eval_C.zip\n",
            "  inflating: dev_task_c_entries.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_aggregated.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfxnQhGyEu8R",
        "outputId": "b3d4b08e-cb52-4009-8c03-af203497eeac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-23 13:58:38--  https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_aggregated.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3846925 (3.7M) [text/plain]\n",
            "Saving to: ‘edos_labelled_aggregated.csv.1’\n",
            "\n",
            "\r          edos_labe   0%[                    ]       0  --.-KB/s               \redos_labelled_aggre 100%[===================>]   3.67M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-02-23 13:58:38 (283 MB/s) - ‘edos_labelled_aggregated.csv.1’ saved [3846925/3846925]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339,
          "referenced_widgets": [
            "167fc474c61b403e82cfab36e041c297",
            "a67cdafbb46e4844a91888cddab9951c",
            "38d294bc14424223b37d187590701022",
            "9807dc09f9c5402395466b55f451deb2",
            "1e927a9947c2478eba65bad5f52b4b08",
            "9d08bd74e725424c9d5505d91547768b",
            "ca606609b41e4cac8f321c9059fcbf7e",
            "311d3520e27f4b6c8d28a76b3477941d",
            "1e4719d6ed6d41c0b8fab61013b8cb7b",
            "f8a93159668d4c33be84a426fe73178d",
            "3059c7c30770496480f6ac6c5463f9ed",
            "3edd9b987515494791d4d2224481eadd",
            "f6fb5c1d61f34a9385bc50e1f87447a0",
            "c5049121269c484a84cb1afdbd8de15a",
            "e784000b752449b9a9b8b7719e464d4f",
            "3a780e04baa949f68580150338c357c4",
            "f89e7eb9f5c14375b8f0ab61f68153c8",
            "fddaec38edec48f1be33e31ad7fe231a",
            "553025da88674d348bc2f2abbbab498d",
            "86cfd6cdf5164091998dc7f2d680eca0",
            "8fa48508494d49efbbf2e23624bd8180",
            "370da98313384bcd8c76f8953cf9128a",
            "1729e26425c14aab8f83d0078f4266d0",
            "a2e8904de1dc4804b4b4ef7e968f6878",
            "a496638544744f31a2200134fe033891",
            "e533e3dde2014b5ababf64ddd58165d7",
            "269877967fd948f8b76fe0376367457c",
            "96de9daac2d446fda452d82be650ac0f",
            "75f79f8d39d440a2bb485bede8b7cfb8",
            "1632aef2ee6e4cabb067ae1f727a4203",
            "ec1a8594b4fb4fc78f515d37886a31a6",
            "f15de7dd41524a2aba5117cecc8541d9",
            "76bb690042924eee8b91d482c33019d4",
            "97fd932f3b0a4fa1b919cd9a397617c8",
            "b5579b53ddfa46919d362f6b4b0ca5ed",
            "daa8ace085d14ed987d1636e411d40f7",
            "c173721c90a84c35a848580548b92994",
            "fa97ddf181b347e3accf5ee8c86d0a4f",
            "9b3e70ef79e54c22945b93c9c663de5c",
            "80b53483bceb415082b6303d43314ecb",
            "23ce4fdbe6bf43619101fd8e0ff1e436",
            "1d046cba47dd490cad0882a7323565bf",
            "a91be9c5e31b43418f7ee568687c2855",
            "0ac707b38fb74b9eb26abdaab77142d0"
          ]
        },
        "id": "GovgvIQHckG9",
        "outputId": "810dc1dd-b768-46f1-caa1-f149c2bcc03e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "167fc474c61b403e82cfab36e041c297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3edd9b987515494791d4d2224481eadd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"spm.model\";:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1729e26425c14aab8f83d0078f4266d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97fd932f3b0a4fa1b919cd9a397617c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import json\n",
        "import pickle\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import transformers\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "from transformers import BertModel, BertTokenizer, DebertaTokenizer, DebertaModel, RobertaTokenizer, RobertaModel, ElectraTokenizer, ElectraModel\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score\n",
        "# from torch_geometric.nn import GCNConv, GATConv, TransformerConv\n",
        "import pandas as pd\n",
        "import os\n",
        "from collections import defaultdict, namedtuple, OrderedDict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from itertools import count \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW, Adam, RMSprop\n",
        "from copy import deepcopy\n",
        "from sklearn.utils import shuffle\n",
        "from typing import Union, Callable\n",
        "import random\n",
        "import gdown\n",
        "from torch import Tensor\n",
        "from typing import Optional, Tuple\n",
        "import pickle as pk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "seeds = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "seed_idx = 1\n",
        "seed = seeds[seed_idx]\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "deberta = 'microsoft/deberta-v3-large' \n",
        "roberta = 'roberta-large'\n",
        "model_name = deberta\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
        "\n",
        "\n",
        "train_data = pd.read_csv('train_all_tasks.csv')\n",
        "eval_data_A = pd.read_csv('dev_task_a_entries.csv')\n",
        "eval_data_B = pd.read_csv('dev_task_b_entries.csv')\n",
        "eval_data_C = pd.read_csv('dev_task_c_entries.csv')\n",
        "all_data_edos = pd.read_csv('edos_labelled_aggregated.csv')\n",
        "\n",
        "\n",
        "def tolist(tensor):\n",
        "  return tensor.detach().cpu().tolist()\n",
        "\n",
        "def map_names_2_ids(names):\n",
        "  A = dict()\n",
        "  B = dict()\n",
        "  for id, name in enumerate(names):\n",
        "    A[name] = id\n",
        "    B[id] = name\n",
        "  return A, B\n",
        "\n",
        "def dist(x1, x2):\n",
        "  return (x1 - x2).pow(2).sum(-1).sqrt()\n",
        "\n",
        "def entropy(logits):\n",
        "  probs = F.softmax(logits, dim=-1)\n",
        "  ent = -torch.sum((probs * torch.log2(probs)),dim=1)\n",
        "  return ent\n",
        "\n",
        "train_data = train_data[train_data['label_sexist'] == 'sexist'].reset_index(drop=True)\n",
        "test_data = deepcopy(all_data_edos[(all_data_edos['split'] == 'test') & (all_data_edos['label_sexist'] =='sexist')]).reset_index(drop=True)\n",
        "\n",
        "label_category_raw = np.unique(train_data['label_category']).tolist()\n",
        "label_category_map, category_label_map = map_names_2_ids(label_category_raw)\n",
        "train_data['Tag_B'] = [label_category_map[i[1]] for i in train_data['label_category'].iteritems()]\n",
        "label_category = list(label_category_map.keys())\n",
        "label_category = list(map(lambda x: re.sub('^\\d+\\.\\d*', '', x).strip(), label_category))\n",
        "eval_label_B = pd.read_csv('dev_task_b_labels.csv')\n",
        "eval_B = eval_data_B.merge(eval_label_B, on='rewire_id')\n",
        "eval_B['Tag_B'] = [label_category_map[i[1]] for i in eval_B['label'].iteritems()]\n",
        "test_data['Tag_B'] = [label_category_map[i[1]] for i in test_data['label_category'].iteritems()]\n",
        "\n",
        "num_labels_B = len(train_data['label_category'].unique())\n",
        "\n",
        "label_vector_raw = np.unique(train_data['label_vector']).tolist()\n",
        "label_vector_map, vector_label_map = map_names_2_ids(label_vector_raw)\n",
        "train_data['Tag_C'] = [label_vector_map[i[1]] for i in train_data['label_vector'].iteritems()]\n",
        "label_vector = list(label_vector_map.keys())\n",
        "label_vector = list(map(lambda x: re.sub('^\\d+\\.\\d*', '', x).strip(), label_vector))\n",
        "eval_label_C = pd.read_csv('dev_task_c_labels.csv')\n",
        "eval_C = eval_data_C.merge(eval_label_C, on='rewire_id')\n",
        "eval_C['Tag_C'] = [label_vector_map[i[1]] for i in eval_C['label'].iteritems()] \n",
        "num_labels_C = len(train_data['label_vector'].unique())\n",
        "\n",
        "train_dataframe = train_data\n",
        "eval_dataframe = eval_B\n",
        "test_dataframe = test_data\n",
        "new_l = label_category\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.array(list(range(num_labels_B))), y=train_data['Tag_B'].values.tolist()).tolist()\n",
        "\n",
        "class SexistDataset(Dataset):\n",
        "\n",
        "  def __init__(self, dataframe, tokenizer, max_length=100, is_test=False):\n",
        "    self.dataframe = dataframe\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    self.labels_names = f'{tokenizer.sep_token}'.join(new_l)\n",
        "    self.is_test = is_test\n",
        "\n",
        "    self.labels_tokens = []\n",
        "    for label_name in new_l:\n",
        "      label_tokens = tokenizer(label_name, add_special_tokens=False)\n",
        "      self.labels_tokens.append(label_tokens['input_ids'])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.dataframe.loc[idx]\n",
        "    tokenized_text = tokenizer(\n",
        "          sample['text'],\n",
        "          max_length=self.max_length,\n",
        "          padding='max_length',\n",
        "          truncation='only_first',\n",
        "          return_tensors='pt')\n",
        "\n",
        "    # find the first token of labels\n",
        "    input_ids = tokenized_text['input_ids']\n",
        "    labels_start = (input_ids == tokenizer.sep_token_id).nonzero().contiguous().view(-1).tolist()[1] + 2\n",
        "\n",
        "    labels_tokens_span = []\n",
        "    c_token = labels_start\n",
        "    # print(labels_start)\n",
        "    for label_tokens in self.labels_tokens:\n",
        "\n",
        "      labels_tokens_span.append([c_token, c_token + len(label_tokens) - 1])\n",
        "      c_token += len(label_tokens) + 1\n",
        "    tokenized_text['labels_tokens_span'] = torch.tensor(labels_tokens_span)\n",
        "    if not self.is_test:\n",
        "      labels_B = torch.LongTensor([sample['Tag_B']])\n",
        "      tokenized_text['Tag_B'] = labels_B\n",
        "    return tokenized_text\n",
        "\n",
        "\n",
        "class UnlabeledDataset:\n",
        "  def __init__(self, dataframe, tokenizer, max_length=70, batch_size=10):\n",
        "    self.data = dataframe\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    self.batch_size = batch_size\n",
        "    self.idxs = np.random.permutation(range(len(self.data)))\n",
        "    self.current_idx = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  def combine_tenors(self, tensors_list):\n",
        "    combined_tensor = dict()\n",
        "    keys = tensors_list[0].keys()\n",
        "    for key in keys:\n",
        "      combined_tensor[key] = torch.cat([tensor[key] for tensor in tensors_list])\n",
        "    return combined_tensor\n",
        "\n",
        "  def next(self):\n",
        "    if self.current_idx >= len(self.data) - 1:\n",
        "      self.current_idx = 0\n",
        "    compact_data = self.data.iloc[self.idxs[self.current_idx: self.current_idx + self.batch_size]]\n",
        "    self.current_idx += self.batch_size\n",
        "    all_t = [self.tokenize(data) for _, data in compact_data.iterrows()]\n",
        "    T = self.combine_tenors(all_t)\n",
        "    return T\n",
        "\n",
        "  def tokenize(self, data):\n",
        "    return self.tokenizer(data['text'], padding='max_length', max_length=self.max_length, truncation=True, return_tensors='pt')\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.sqrt_dim = np.sqrt(dim)\n",
        "\n",
        "    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:\n",
        "        score = torch.bmm(query, key.transpose(1, 2)) / self.sqrt_dim\n",
        "\n",
        "        if mask is not None:\n",
        "            score.masked_fill_(mask.view(score.size()), -float('Inf'))\n",
        "\n",
        "        attn = F.softmax(score, -1)\n",
        "        context = torch.bmm(attn, value)\n",
        "        return context, attn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int = 512, num_heads: int = 8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        assert d_model % num_heads == 0, \"d_model % num_heads should be zero.\"\n",
        "\n",
        "        self.d_head = int(d_model / num_heads)\n",
        "        self.num_heads = num_heads\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.d_head)\n",
        "        self.query_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
        "        self.key_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
        "        self.value_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            query: Tensor,\n",
        "            key: Tensor,\n",
        "            value: Tensor,\n",
        "            mask: Optional[Tensor] = None\n",
        "    ) -> Tuple[Tensor, Tensor]:\n",
        "        batch_size = value.size(0)\n",
        "\n",
        "        query = self.query_proj(query).view(batch_size, -1, self.num_heads, self.d_head)  # BxQ_LENxNxD\n",
        "        key = self.key_proj(key).view(batch_size, -1, self.num_heads, self.d_head)      # BxK_LENxNxD\n",
        "        value = self.value_proj(value).view(batch_size, -1, self.num_heads, self.d_head)  # BxV_LENxNxD\n",
        "\n",
        "        query = query.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)  # BNxQ_LENxD\n",
        "        key = key.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)      # BNxK_LENxD\n",
        "        value = value.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.d_head)  # BNxV_LENxD\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1).repeat(1, self.num_heads, 1, 1)  # BxNxQ_LENxK_LEN\n",
        "\n",
        "        context, attn = self.scaled_dot_attn(query, key, value, mask)\n",
        "\n",
        "        context = context.view(self.num_heads, batch_size, -1, self.d_head)\n",
        "        context = context.permute(1, 2, 0, 3).contiguous().view(batch_size, -1, self.num_heads * self.d_head)  # BxTxND\n",
        "\n",
        "        return context, attn\n",
        "\n",
        "def exists(value):\n",
        "    return value is not None\n",
        "\n",
        "\n",
        "def default(value, default):\n",
        "    if exists(value):\n",
        "        return value\n",
        "    return default\n",
        "\n",
        "\n",
        "def inf_norm(x):\n",
        "    return torch.norm(x, p=float(\"inf\"), dim=-1, keepdim=True)\n",
        "\n",
        "\n",
        "def kl_loss(input, target, reduction=\"batchmean\"):\n",
        "    return F.kl_div(\n",
        "        F.log_softmax(input, dim=-1),\n",
        "        F.softmax(target, dim=-1),\n",
        "        reduction=reduction,\n",
        "    )\n",
        "\n",
        "\n",
        "def sym_kl_loss(input, target, reduction=\"batchmean\", alpha=1.0):\n",
        "    return alpha * F.kl_div(\n",
        "        F.log_softmax(input, dim=-1),\n",
        "        F.softmax(target.detach(), dim=-1),\n",
        "        reduction=reduction,\n",
        "    ) + F.kl_div(\n",
        "        F.log_softmax(target, dim=-1),\n",
        "        F.softmax(input.detach(), dim=-1),\n",
        "        reduction=reduction,\n",
        "    )\n",
        "\n",
        "\n",
        "def js_loss(input, target, reduction=\"batchmean\", alpha=1.0):\n",
        "    mean_proba = 0.5 * (\n",
        "        F.softmax(input.detach(), dim=-1) + F.softmax(target.detach(), dim=-1)\n",
        "    )\n",
        "    return alpha * (\n",
        "        F.kl_div(F.log_softmax(input, dim=-1), mean_proba, reduction=reduction)\n",
        "        + F.kl_div(F.log_softmax(target, dim=-1), mean_proba, reduction=reduction)\n",
        "    )\n",
        "\n",
        "\n",
        "def ntxent(logits, labels, temp=.07):\n",
        "  def ntx_loss(a, p, n, temp=temp):\n",
        "    a = a.unsqueeze(0) if a.dim() == 1 else a\n",
        "    p = p.unsqueeze(0) if p.dim() == 1 else p\n",
        "    n = n.unsqueeze(0) if n.dim() == 1 else n\n",
        "    assert a.dim() == 2\n",
        "    assert p.dim() == 2\n",
        "    assert n.dim() == 2\n",
        "    a_p = a\n",
        "    a_n = a.repeat(n.shape[0], 1)\n",
        "    p_sim = F.cosine_similarity(a_p, p, dim=-1) / temp\n",
        "    n_sim = F.cosine_similarity(a_n, n, dim=-1) / temp\n",
        "\n",
        "    # apply numeric stability\n",
        "    max_val = torch.max(n_sim).detach()\n",
        "    numerator = torch.exp(p_sim - max_val)\n",
        "    denominator = torch.exp(n_sim - max_val).sum()\n",
        "    loss = -torch.log(numerator / (denominator + numerator) + 1e-6)\n",
        "    if loss.isnan():\n",
        "      print(numerator, denominator)\n",
        "      print(p_sim)\n",
        "      print(len(n))\n",
        "    # print(loss)\n",
        "    return loss.mean()\n",
        "\n",
        "  def dist(x1, x2):\n",
        "    return (x1 - x2).pow(2).sum(-1).sqrt()\n",
        "\n",
        "  con_losses = list()\n",
        "  for i, (logit, label) in enumerate(zip(logits, labels)):\n",
        "    ps = (labels == label)\n",
        "    ns = (labels != label).nonzero().view(-1)\n",
        "    ps[i] = False\n",
        "    ps = ps.nonzero().view(-1)\n",
        "    if len(ns):\n",
        "      for p in ps:\n",
        "        a_logit = logits[i]\n",
        "        p_logit = logits[p]\n",
        "        ns_logit = logits[ns]\n",
        "        A = ntx_loss(a_logit, p_logit, ns_logit)\n",
        "        con_losses.append(A)\n",
        "\n",
        "  if len(con_losses) > 0:\n",
        "    all_con_loss = torch.stack(con_losses).mean()\n",
        "  else:\n",
        "    all_con_loss = torch.tensor(0.)\n",
        "  return all_con_loss\n",
        "\n",
        "\n",
        "class SMARTLoss(nn.Module):\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        loss_fn: Callable,\n",
        "        loss_last_fn: Callable = None, \n",
        "        norm_fn: Callable = inf_norm, \n",
        "        num_steps: int = 1,\n",
        "        step_size: float = 1e-3, \n",
        "        epsilon: float = 1e-6,\n",
        "        noise_var: float = 1e-5\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.model = model \n",
        "        self.loss_fn = loss_fn\n",
        "        self.loss_last_fn = default(loss_last_fn, loss_fn)\n",
        "        self.norm_fn = norm_fn\n",
        "        self.num_steps = num_steps \n",
        "        self.step_size = step_size\n",
        "        self.epsilon = epsilon \n",
        "        self.noise_var = noise_var\n",
        "     \n",
        "    @torch.enable_grad()   \n",
        "    def forward(self, embed, state, batch_labels_tokens_span, attention_mask):\n",
        "        noise = torch.randn_like(embed, requires_grad = True) * self.noise_var \n",
        "        \n",
        "        # Indefinite loop with counter \n",
        "        for i in count():\n",
        "            # Compute perturbed embed and states \n",
        "            embed_perturbed = embed + noise \n",
        "            state_perturbed, _ = self.model(embed_perturbed, batch_labels_tokens_span, True, attention_mask) \n",
        "            # Return final loss if last step (undetached state)\n",
        "            if i == self.num_steps: \n",
        "                return self.loss_last_fn(state_perturbed, state) \n",
        "            # Compute perturbation loss (detached state)\n",
        "            loss = self.loss_fn(state_perturbed, state.detach())\n",
        "            # Compute noise gradient ∂loss/∂noise\n",
        "            noise_gradient, = torch.autograd.grad(loss, noise)\n",
        "            # Move noise towards gradient to change state as much as possible \n",
        "            step = noise + self.step_size * noise_gradient \n",
        "            # Normalize new noise step into norm induced ball \n",
        "            step_norm = self.norm_fn(step)\n",
        "            noise = step / (step_norm + self.epsilon)\n",
        "            # Reset noise gradients for next step\n",
        "            noise = noise.detach().requires_grad_()\n",
        "\n",
        "class PGD():\n",
        "\n",
        "    def __init__(self, model,emb_name,epsilon=1.,alpha=0.3):\n",
        "        # The emb_name parameter should be replaced with the parameter name of the embedding in your model\n",
        "        self.model = model\n",
        "        self.emb_name = emb_name\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.emb_backup = {}\n",
        "        self.grad_backup = {}\n",
        "\n",
        "    # adversarial training : attack to change embedding abit with regards projected gradiant descent\n",
        "    def attack(self,first_strike=False):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and self.emb_name in name:\n",
        "                if first_strike:\n",
        "                    # print('tt', param.data)\n",
        "                    self.emb_backup[name] = param.data.clone()\n",
        "                norm = torch.norm(param.grad)\n",
        "                if norm != 0:\n",
        "                    # Compute new params\n",
        "                    r_at = self.alpha * param.grad / norm\n",
        "                    param.data.add_(r_at)\n",
        "                    param.data = self.project(name, param.data, self.epsilon)\n",
        "\n",
        "    # Restore to the back-up embeddings\n",
        "    def restore(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and self.emb_name in name:\n",
        "                assert name in self.emb_backup\n",
        "                param.data = self.emb_backup[name]\n",
        "        self.emb_backup = {}\n",
        "\n",
        "    # Project Gradiant Descent\n",
        "    def project(self, param_name, param_data, epsilon):\n",
        "        r = param_data - self.emb_backup[param_name]\n",
        "        if torch.norm(r) > epsilon:\n",
        "            r = epsilon * r / torch.norm(r)\n",
        "        return self.emb_backup[param_name] + r\n",
        "\n",
        "    # Back-up parameters\n",
        "    def backup_grad(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and 'pooler' not in name:\n",
        "                self.grad_backup[name] = param.grad.clone()\n",
        "\n",
        "    # Restore grad parameters\n",
        "    def restore_grad(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and 'pooler' not in name:\n",
        "                param.grad = self.grad_backup[name]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SexistModel(nn.Module):\n",
        "\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.transformer = model\n",
        "        hidden_size = self.transformer.config.hidden_size\n",
        "        self.dropout = nn.Dropout(p=.3)\n",
        "        self.head = nn.Linear(hidden_size, num_labels_B)\n",
        "\n",
        "    def integrate(self, batch_output, batch_labels_tokens_span):\n",
        "      batch_size = batch_output.shape[0]\n",
        "      integrated_batch = []\n",
        "      for i in range(batch_size):\n",
        "        integrated_sample_labels = []\n",
        "        output = batch_output[i]\n",
        "        labels_tokens_span = batch_labels_tokens_span[i]\n",
        "        for label_tokens_span in labels_tokens_span:\n",
        "          integrated_label = output[label_tokens_span[0].item(): label_tokens_span[1].item() + 1].mean(0).view(-1)\n",
        "          assert integrated_label.shape[0] == self.transformer.config.hidden_size\n",
        "          integrated_sample_labels.append(integrated_label)\n",
        "        integrated_sample_labels = torch.stack(integrated_sample_labels)\n",
        "        integrated_batch.append(integrated_sample_labels)\n",
        "      integrated_batch = torch.stack(integrated_batch)\n",
        "      return integrated_batch\n",
        "\n",
        "    def forward(self, x, batch_labels_tokens_span, vat=False, attention_mask=None):\n",
        "        if vat:\n",
        "          hidden = self.transformer(inputs_embeds=x, attention_mask=attention_mask).last_hidden_state\n",
        "        else:\n",
        "          hidden = self.transformer(**x).last_hidden_state\n",
        "        cls = hidden[:, 0, :]\n",
        "        x = self.head(cls)\n",
        "        x = x.view(-1, num_labels_B)\n",
        "        return x, hidden[:, 0, :]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(dataloader, model, device, loss_fn, optimizer, scheduler, stage, ul_dataset, use_contrastive=False,\n",
        "          use_adv=True, use_vadv=False, use_ul=False, vat_weight=.5, ul_weight=.5, con_weight=.5, adv_use_every_layer=True):\n",
        "  \n",
        "  model.train()\n",
        "  named_weights = [n for n, _ in model.named_parameters() if 'dense.weight' in n and 'pooler' not in n] + [\"word_embeddings.\"]\n",
        "  loss_collection = [[], [], [], [], []]\n",
        "  for step, data in enumerate(dataloader):\n",
        "\n",
        "    if adv_use_every_layer:\n",
        "      rand_layer = random.sample(named_weights, 1)[0] \n",
        "      adv_layer = rand_layer\n",
        "    else:\n",
        "      adv_rand = random.uniform(0, 1) \n",
        "      if adv_rand > .7:\n",
        "        adv_layer = \"word_embeddings.\"\n",
        "      else:\n",
        "        rand_layer = random.sample(named_weights, 1)[0] \n",
        "        adv_layer = rand_layer\n",
        "    pgd = PGD(\n",
        "      model=model,\n",
        "      emb_name=adv_layer\n",
        "    )\n",
        "\n",
        "\n",
        "    c_batch_size = data['input_ids'].shape[0]\n",
        "    labels = data.pop('Tag_B').to(device).view(-1)\n",
        "    for key in data:\n",
        "      data[key] = data[key].to(device).view(c_batch_size, -1)\n",
        "    batch_labels_tokens_span = data.pop('labels_tokens_span').view(-1, num_labels_B, 2)\n",
        "\n",
        "    logits, _ = model(data, batch_labels_tokens_span)\n",
        "\n",
        "    ce_loss = loss_fn(logits, labels)\n",
        "    ce_loss.backward()\n",
        "    loss_collection[0].append(ce_loss.item())\n",
        "\n",
        "\n",
        "    \n",
        "    if use_adv:\n",
        "      # PGD Start\n",
        "        pgd.backup_grad()\n",
        "        attack_times = 2\n",
        "        for attack_time in range(attack_times):\n",
        "            # Add adversarial perturbation to the embedding, backup param.data during the first attack\n",
        "            pgd.attack(first_strike=(attack_time==0))\n",
        "            if attack_time != attack_times-1:\n",
        "              model.zero_grad()\n",
        "            else:\n",
        "              pgd.restore_grad()\n",
        "            logits_adv, _ = model(data, batch_labels_tokens_span)\n",
        "            loss_adv = loss_fn(logits_adv, labels)\n",
        "            loss_collection[1].append(loss_adv.item())\n",
        "            loss_adv.backward()\n",
        "        # Restore embedding parameters\n",
        "        pgd.restore() \n",
        "\n",
        "    if use_contrastive:\n",
        "      embeddings = model.get_embeddings(data['input_ids'].to(device))\n",
        "      model.set_attention_mask(data['attention_mask'].to(device))\n",
        "      logits = model(embeddings, batch_labels_tokens_span)\n",
        "      con_loss = ntxent(logits, labels) * con_weight\n",
        "      if con_loss.requires_grad:\n",
        "        con_loss.backward()\n",
        "      loss_collection[2].append(con_loss.item())\n",
        "\n",
        "\n",
        "    if use_vadv:\n",
        "      vat_loss_fn = SMARTLoss(model = model, loss_fn = kl_loss, loss_last_fn = sym_kl_loss)\n",
        "      # Compute VAT loss\n",
        "      embeddings = model.transformer.embeddings(data['input_ids'], data['token_type_ids'])\n",
        "      logits, _ = model(embeddings, batch_labels_tokens_span, True, data['attention_mask'])\n",
        "      vat_loss = vat_loss_fn(embeddings, logits, batch_labels_tokens_span, data['attention_mask']) \n",
        "      # Merge losses \n",
        "      vat_loss = vat_weight * vat_loss\n",
        "      vat_loss.backward()\n",
        "      loss_collection[3].append(vat_loss.item())    \n",
        "\n",
        "\n",
        "    if use_ul:\n",
        "      ul_data = ul_dataset.next()\n",
        "      c_batch_size = ul_data['input_ids'].shape[0]\n",
        "      for key in ul_data:\n",
        "        ul_data[key] = ul_data[key].to(device).view(c_batch_size, -1)\n",
        "\n",
        "      ul_embeddings = model.get_embeddings(ul_data['input_ids'].to(device))\n",
        "      model.set_attention_mask(ul_data['attention_mask'].to(device))\n",
        "      ul_logits = model(ul_embeddings)\n",
        "\n",
        "      vat_loss_fn = SMARTLoss(model = model, loss_fn = kl_loss, loss_last_fn = sym_kl_loss)\n",
        "      vat_loss = vat_loss_fn(ul_embeddings, ul_logits) \n",
        "      ul_loss = ul_weight * vat_loss\n",
        "      loss_collection[4].append(ul_loss.item())\n",
        "      ul_loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    scheduler.step()\n",
        "    \n",
        "    if len(loss_collection[0]) % log_step == 0:\n",
        "      print(f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step + 1}/{len(train_dataloader)}] | CE Loss {round(sum(loss_collection[0]) / (len(loss_collection[0]) + 1e-8), 4)}')\n",
        "      print(f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step + 1}/{len(train_dataloader)}] | ADV Loss {round(sum(loss_collection[1]) / (len(loss_collection[1]) + 1e-8), 4)}')\n",
        "      print(f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step + 1}/{len(train_dataloader)}] | CON Loss {round(sum(loss_collection[2]) / (len(loss_collection[2]) + 1e-8), 4)}')\n",
        "      print(f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step + 1}/{len(train_dataloader)}] | VAT Loss {round(sum(loss_collection[3]) / (len(loss_collection[3]) + 1e-8), 4)}')\n",
        "      print(f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step + 1}/{len(train_dataloader)}] | UL Loss {round(sum(loss_collection[4]) / (len(loss_collection[4]) + 1e-8), 4)}')\n",
        "      print('------------------------------------------------')\n",
        "      loss_collection = [[] for _ in range(5)]\n",
        "\n",
        "\n",
        "def eval(dataloader, model, device):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    all_preds = list()\n",
        "    all_hidden = list()\n",
        "    for data in dataloader:\n",
        "      c_batch_size = data['input_ids'].shape[0]\n",
        "      for key in data:\n",
        "        data[key] = data[key].to(device).view(c_batch_size, -1)\n",
        "      batch_labels_tokens_span = data.pop('labels_tokens_span').view(-1, num_labels_B, 2)\n",
        "      Tag_B = data.pop('Tag_B').to(device).view(-1)\n",
        "      logits, hiddens = model(data, batch_labels_tokens_span)\n",
        "      all_hidden.extend(tolist(hiddens))\n",
        "      preds = tolist(logits.argmax(1).view(-1))\n",
        "      all_preds.extend(preds)\n",
        "  return all_preds, all_hidden\n",
        "\n",
        "\n",
        "def test(dataloader, model, device):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    all_preds = list()\n",
        "\n",
        "    for data in dataloader:\n",
        "      c_batch_size = data['input_ids'].shape[0]\n",
        "      for key in data:\n",
        "        data[key] = data[key].to(device).view(c_batch_size, -1)\n",
        "      batch_labels_tokens_span = data.pop('labels_tokens_span').view(-1, num_labels_B, 2)\n",
        "      logits, _ = model(data, batch_labels_tokens_span)\n",
        "      preds = tolist(logits.argmax(1).view(-1))\n",
        "      all_preds.extend(preds)\n",
        "  return all_preds\n",
        "\n",
        "epochs = 30\n",
        "lr = 1e-5\n",
        "beta_1 = .9\n",
        "beta_2 = .999\n",
        "eps = 1e-6\n",
        "log_step = 100\n",
        "batch_size = 10\n",
        "weight_decay = 9e-3\n",
        "max_length = 70\n",
        "loss_file = 'loss.txt'\n",
        "eval_file = 'eval.txt'\n",
        "\n",
        "vat_weight = .5\n",
        "ul_weight = .5\n",
        "ent_weight = .5\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "# sexist_model = ExtractedRoBERTa(deepcopy(model)).to(device)\n",
        "sexist_model = SexistModel(deepcopy(model)).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device)).to(device)\n",
        "loss_collection = []\n",
        "\n",
        "train_dataset = SexistDataset(train_dataframe, tokenizer, max_length)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "eval_dataset = SexistDataset(eval_dataframe, tokenizer, max_length)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = SexistDataset(test_dataframe, tokenizer, max_length)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "opt_step = 0\n",
        "optimization_steps = epochs * len(train_dataloader)\n",
        "warmup_ratio = .0\n",
        "warmup_steps = int(optimization_steps * warmup_ratio)\n",
        "\n",
        "\n",
        "optimizer = AdamW(sexist_model.parameters(), lr=lr, betas=(beta_1,beta_2), eps=eps, weight_decay=weight_decay)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=warmup_steps, \n",
        "    num_training_steps=optimization_steps)\n",
        "\n",
        "best_f1 = 0.\n",
        "best_model = None\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_dir = '.'\n",
        "filename = os.path.join(checkpoint_dir, 'best_ch.pt')\n",
        "\n",
        "\n",
        "def save_model(epoch, model, optimizer, scheduler):\n",
        "  filename = os.path.join(checkpoint_dir, 'best_ch.pt')\n",
        "  torch.save(\n",
        "      {'epoch': epoch,\n",
        "       'model_state_dict': model.state_dict(),\n",
        "       'optimizer_state_dict': optimizer.state_dict(),\n",
        "       'scheduler_state_dict': scheduler.state_dict()}, \n",
        "        filename)\n",
        "\n",
        "def load_model():\n",
        "  if os.path.exists(filename):\n",
        "    saved_dict = torch.load(filename)\n",
        "    return True, saved_dict\n",
        "  else:\n",
        "    return False, None\n",
        "    \n",
        "\n",
        "def early_stop(scores, current_score, patience):\n",
        "  if len(scores) < patience:\n",
        "    return False\n",
        "  else:\n",
        "    for score in scores[-patience: ]:\n",
        "      if current_score > score:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "all_f1 = list()\n",
        "patience = 2\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#   train(train_dataloader, sexist_model, device, loss_fn, optimizer, scheduler, 1, None)\n",
        "#   preds_B_eval = eval(eval_dataloader, sexist_model, device)\n",
        "#   f1_macro_B_eval = f1_score(eval_dataframe['Tag_B'].values.tolist(), preds_B_eval, average='macro')\n",
        "#   all_f1.append(f1_macro_B_eval)\n",
        "#   if f1_macro_B_eval > best_f1:\n",
        "#     best_f1 = f1_macro_B_eval\n",
        "#     best_preds = preds_B_eval\n",
        "#     save_model(epoch + 1, sexist_model, optimizer, scheduler)\n",
        "\n",
        "#   print(f'EPOCH [{epoch + 1}/{epochs}] | Current F1-Macro {round(f1_macro_B_eval * 100, 2)}')\n",
        "#   print(f'EPOCH [{epoch + 1}/{epochs}] | Best F1-Macro {round(best_f1 * 100, 2)}')\n",
        "#   print(confusion_matrix(eval_dataframe['Tag_B'].values.tolist(), preds_B_eval))\n",
        "\n",
        "#   if early_stop(all_f1, f1_macro_B_eval, patience):\n",
        "#     break\n",
        "#   else:\n",
        "#     print('not early stopping')\n",
        "\n",
        "\n",
        "_, saved_dict = load_model()\n",
        "sexist_model.load_state_dict(saved_dict['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(dataloader, model, device):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    all_preds = list()\n",
        "    all_hidden = list()\n",
        "    for data in dataloader:\n",
        "      c_batch_size = data['input_ids'].shape[0]\n",
        "      for key in data:\n",
        "        data[key] = data[key].to(device).view(c_batch_size, -1)\n",
        "      batch_labels_tokens_span = data.pop('labels_tokens_span').view(-1, num_labels_B, 2)\n",
        "      Tag_B = data.pop('Tag_B').to(device).view(-1)\n",
        "      logits, hiddens = model(data, batch_labels_tokens_span)\n",
        "      all_hidden.extend(tolist(hiddens))\n",
        "      preds = tolist(logits.argmax(1).view(-1))\n",
        "      all_preds.extend(preds)\n",
        "  return all_preds, all_hidden"
      ],
      "metadata": {
        "id": "WHsf8e3ljG0s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  preds_B_test, _ = eval(test_dataloader, sexist_model, device)\n",
        "  f1_macro_B_test = f1_score(test_data['Tag_B'].values.tolist(), preds_B_test, average='macro')"
      ],
      "metadata": {
        "id": "KY6Nt0JKkBcw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_nu0mXuyp-u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_B_test, _ = eval(test_dataloader, sexist_model, device)\n",
        "f1_macro_B_test = f1_score(test_data['Tag_B'].values.tolist(), preds_B_test, average='macro')\n",
        "pr_B_test = precision_score(test_data['Tag_B'].values.tolist(), preds_B_test, average='macro')\n",
        "rc_B_test = recall_score(test_data['Tag_B'].values.tolist(), preds_B_test, average='macro')"
      ],
      "metadata": {
        "id": "lxAcBA2syqAZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = confusion_matrix(test_data['Tag_B'].values.tolist(), preds_B_test)"
      ],
      "metadata": {
        "id": "l6gUewYzEC_Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_macro_B_test, pr_B_test, rc_B_test"
      ],
      "metadata": {
        "id": "NzKqkghpGUkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e27178-d70c-42a4-aad5-733cf45f88cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6778446509164594, 0.6916144996583754, 0.6775330287366629)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tiFSk6LZH4T_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtnwFRUeEDIl"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}